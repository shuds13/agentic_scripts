#!/usr/bin/env python3
"""
Interactive LangChain agent for libEnsemble script generation and execution.

LLM-first approach: the agent has tools and the chat IS the agent loop.
Each user message is a real HumanMessage. The agent responds with tool
calls and/or text. No fake 'ask_user' workaround.

Without --interactive, it runs autonomously in a single invocation.

Requirements: pip install langchain langchain-openai mcp openai
              (add langchain-anthropic for Claude models)
For options: python libe_agent_interactive_llm_first.py -h
"""

import os
import sys
import asyncio
import re
import subprocess
import argparse
import shutil
import time
from pathlib import Path
from typing import Optional
from pydantic import BaseModel, Field, create_model
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain_core.tools import StructuredTool
from langchain_core.messages import HumanMessage
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client


DEFAULT_OPENAI_MODEL = "gpt-4o-mini"
DEFAULT_ANTHROPIC_MODEL = "claude-sonnet-4-20250514"
if os.environ.get("LLM_MODEL"):
    MODEL = os.environ["LLM_MODEL"]
elif os.environ.get("OPENAI_API_KEY") or not os.environ.get("ANTHROPIC_API_KEY"):
    MODEL = DEFAULT_OPENAI_MODEL
else:
    MODEL = DEFAULT_ANTHROPIC_MODEL
SHOW_PROMPTS = False

ARCHIVE_RUNS_DIR = "archive_runs"
SKILLS_DIR = Path(__file__).parent / "skills"

INPUT_MARKER = "[INPUT_REQUESTED]"

DEFAULT_PROMPT = """Create six_hump_camel APOSMM scripts:
- Executable: /home/shudson/test_mcp/script-creator/six_hump_camel/six_hump_camel.x
- Input: /home/shudson/test_mcp/script-creator/six_hump_camel/input.txt
- Template vars: X0, X1
- 4 workers, 100 sims.
- The output file for each simulation is output.txt
- The bounds should be 0,1 and -1,2 for X0 and X1 respectively"""

SYSTEM_PROMPT = """You are a libEnsemble script assistant. You help users generate, review, modify, and run libEnsemble scripts for parallel optimization.

You have these tools:
- CreateLibEnsembleScripts: Generate initial scripts from a description. Call it ONCE per session. Pass ALL user-specified values as tool parameters (sim_app, input_path, num_workers, max_sims, template_vars, etc.).
- read_file: Read a script to inspect it.
- write_file: Modify a script (read it first, then write the full updated content).
- run_script: Run a script. Only do this when the user asks.
- list_files: List available scripts.

Rules:
- When calling CreateLibEnsembleScripts, extract EVERY detail from the user's request and pass it as a tool parameter. Especially sim_app (executable path), input_path, template_vars, num_workers, max_sims.
- Only call CreateLibEnsembleScripts ONCE. For all later modifications, use read_file + write_file.
- After generating, read each file and verify that sim_app, bounds (lb/ub), sim_max, and num_workers match what the user asked for. If a value is wrong, fix ONLY that value — do not rewrite or restructure anything else.
- The generated simf.py launches an external executable — that is the correct structure. You may fix specific values in it (e.g. output filename), but NEVER replace it with a direct Python function implementation.
- Do not change the overall structure of generated scripts. Only fix specific values to match the user's request.
- Not every user message requires a tool call. If the user asks a question, just answer it. If they ask to see something, use read_file and show it. Only use tools when the user is asking you to do something to the scripts.
- Don't run scripts unless asked.
- Be concise. Don't repeat the full script content unless asked.

{skills_context}"""

ARCHIVE_ITEMS = [
    "ensemble", "ensemble.log", "libE_stats.txt",
    "*.npy", "*.pickle",
]

# Global state
mcp_session = None
WORK_DIR = None
ARCHIVE_COUNTER = 1
CURRENT_ARCHIVE = None
USER_PROMPT = None
DEBUG_LOG = None


# ── Skills ───────────────────────────────────────────────────

def load_skills():
    """Load skill files from the skills directory. Returns combined text for the system prompt."""
    if not SKILLS_DIR.exists():
        return ""
    parts = []
    for f in sorted(SKILLS_DIR.glob("*.md")):
        parts.append(f.read_text().strip())
    if not parts:
        return ""
    return "Reference information:\n\n" + "\n\n---\n\n".join(parts)


# ── Debug logging ─────────────────────────────────────────────

def dump_messages(messages, label=""):
    """Write full message history to DEBUG_LOG file."""
    if not DEBUG_LOG:
        return
    with open(DEBUG_LOG, "a") as f:
        f.write(f"\n{'='*80}\n")
        if label:
            f.write(f"  {label}\n{'='*80}\n")
        for msg in messages:
            role = type(msg).__name__
            f.write(f"\n--- {role} ---\n")
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                f.write("[Tool calls]\n")
                for tc in msg.tool_calls:
                    f.write(f"  {tc.get('name', '?')}({tc.get('args', {})})\n")
            content = msg.content if isinstance(msg.content, str) else str(msg.content)
            if content:
                if len(content) > 2000:
                    f.write(content[:1000] + f"\n... [{len(content)} chars total] ...\n" + content[-500:] + "\n")
                else:
                    f.write(content + "\n")
        f.write(f"\n{'='*80}\n\n")


# ── Archive helpers ──────────────────────────────────────────

def archive_existing_output_dir(output_dir, archive_parent=None):
    """If output_dir exists, move it to archive_parent/output_dir_<unique>, then create fresh."""
    output_dir = Path(output_dir)
    archive_dir = Path(archive_parent or ARCHIVE_RUNS_DIR)
    if not output_dir.exists():
        output_dir.mkdir(parents=True, exist_ok=True)
        return
    archive_dir.mkdir(parents=True, exist_ok=True)
    dest = archive_dir / f"{output_dir.name}_{hex(time.time_ns())[2:10]}"
    shutil.move(str(output_dir), str(dest))
    print(f"Moved existing {output_dir} to {dest}")
    output_dir.mkdir(parents=True, exist_ok=True)


def start_new_archive(action):
    global ARCHIVE_COUNTER, CURRENT_ARCHIVE
    CURRENT_ARCHIVE = f"{ARCHIVE_COUNTER}_{action}"
    (WORK_DIR / "versions" / CURRENT_ARCHIVE).mkdir(parents=True, exist_ok=True)
    ARCHIVE_COUNTER += 1


def archive_current_scripts():
    if not CURRENT_ARCHIVE:
        return
    dest = WORK_DIR / "versions" / CURRENT_ARCHIVE
    for f in WORK_DIR.glob("*.py"):
        shutil.copy(f, dest / f.name)


def archive_run_output(error_msg=""):
    if not CURRENT_ARCHIVE:
        return
    output_dir = WORK_DIR / "versions" / CURRENT_ARCHIVE / "output"
    output_dir.mkdir(parents=True, exist_ok=True)
    if error_msg:
        (output_dir / "error.txt").write_text(error_msg)
    for item in ARCHIVE_ITEMS:
        item_path = WORK_DIR / item
        if item_path.exists() and item_path.is_dir():
            shutil.copytree(str(item_path), str(output_dir / item), dirs_exist_ok=True)
            shutil.rmtree(str(item_path))
        else:
            for fp in WORK_DIR.glob(item):
                if fp.is_file():
                    shutil.copy(str(fp), str(output_dir / fp.name))
                    fp.unlink()


# ── MCP schema conversion ────────────────────────────────────

JSON_TO_PYTHON = {"string": str, "boolean": bool, "integer": int, "number": float}

def mcp_tool_to_pydantic(mcp_tool):
    """Convert an MCP tool's JSON inputSchema to a Pydantic model.

    Without this, StructuredTool receives a raw dict and the LLM never
    sees the parameter names or descriptions — so it can't fill them in.
    """
    props = mcp_tool.inputSchema.get("properties", {})
    field_defs = {}
    for name, spec in props.items():
        if spec.get("type") == "array":
            py_type = list
        else:
            py_type = JSON_TO_PYTHON.get(spec.get("type"), str)
        field_defs[name] = (Optional[py_type], Field(default=None, description=spec.get("description", "")))
    return create_model(mcp_tool.name + "Input", **field_defs)


# ── Tool schemas ─────────────────────────────────────────────

class RunScriptInput(BaseModel):
    script_name: str = Field(description="Name of the Python script to run")

class ReadFileInput(BaseModel):
    filepath: str = Field(description="Path to file relative to work directory")

class WriteFileInput(BaseModel):
    filepath: str = Field(description="Path to file relative to work directory")
    content: str = Field(description="Full content to write")

class ListFilesInput(BaseModel):
    pass


# ── Tool implementations ────────────────────────────────────

async def run_script_tool(script_name: str) -> str:
    script_path = WORK_DIR / script_name
    if not script_path.exists():
        return f"ERROR: Script '{script_name}' not found"

    print(f"\nRunning {script_name}...", flush=True)
    try:
        result = subprocess.run(
            ["python", script_name], cwd=WORK_DIR,
            capture_output=True, text=True, timeout=300
        )
        if result.returncode == 0:
            print("✓ Script ran successfully", flush=True)
            return f"SUCCESS\nOutput:\n{result.stdout[:500]}"
        else:
            error_msg = f"Return code {result.returncode}\nStderr: {result.stderr}\nStdout: {result.stdout}"
            print(f"✗ Failed (code {result.returncode})", flush=True)
            archive_run_output(error_msg)
            return f"FAILED (code {result.returncode})\nStderr:\n{result.stderr}\nStdout:\n{result.stdout[:500]}"
    except subprocess.TimeoutExpired:
        return "ERROR: Script timed out (300s)"
    except Exception as e:
        return f"ERROR: {e}"


async def read_file_tool(filepath: str) -> str:
    file_path = WORK_DIR / filepath
    if not file_path.exists():
        return f"ERROR: File '{filepath}' not found"
    return file_path.read_text()


async def write_file_tool(filepath: str, content: str) -> str:
    try:
        (WORK_DIR / filepath).write_text(content)
        start_new_archive("fix")
        archive_current_scripts()
        print(f"- Saved: {WORK_DIR / filepath}", flush=True)
        return f"SUCCESS: Wrote {filepath}"
    except Exception as e:
        return f"ERROR: {e}"


async def list_files_tool() -> str:
    py_files = list(WORK_DIR.glob("*.py"))
    if not py_files:
        return "No Python files found"
    return "Files:\n" + "\n".join(f"- {f.name}" for f in py_files)


async def generate_scripts_mcp(**kwargs):
    """Call MCP tool to generate scripts, auto-save to work dir."""
    kwargs.pop('custom_set_objective', None)
    kwargs.pop('set_objective_code', None)

    result = await mcp_session.call_tool("CreateLibEnsembleScripts", kwargs)
    scripts_text = result.content[0].text if result.content else ""

    if scripts_text and "===" in scripts_text:
        WORK_DIR.mkdir(exist_ok=True)
        pattern = r"=== (.+?) ===\n(.*?)(?=\n===|$)"
        for filename, content in re.findall(pattern, scripts_text, re.DOTALL):
            (WORK_DIR / filename.strip()).write_text(content.strip() + "\n")
            print(f"- Saved: {WORK_DIR / filename.strip()}", flush=True)
        start_new_archive("generated")
        archive_current_scripts()

    reminder = (
        "\n\nScripts generated. Now read each file and verify that sim_app, "
        "bounds (lb/ub), sim_max, and num_workers match the user's request below. "
        "If any specific value is wrong, fix ONLY that value with write_file. "
        "Do NOT rewrite or restructure the scripts."
    )
    if USER_PROMPT:
        reminder += f"\n\nUser's request:\n{USER_PROMPT}\n"
    return scripts_text + reminder


# ── LLM factory ──────────────────────────────────────────────

def create_llm(model, temperature=0, base_url=None):
    """Create LLM — ChatAnthropic for Claude models, ChatOpenAI otherwise."""
    if "claude" in model.lower():
        try:
            from langchain_anthropic import ChatAnthropic
        except ImportError:
            sys.exit("Error: pip install langchain-anthropic required for Claude models")
        return ChatAnthropic(model=model, temperature=temperature)
    return ChatOpenAI(model=model, temperature=temperature, base_url=base_url)


# ── MCP server discovery ────────────────────────────────────

def find_mcp_server(user_path=None):
    locations = []
    if user_path:
        locations.append(Path(user_path))
    env_path = os.environ.get('GENERATOR_MCP_SERVER')
    if env_path:
        locations.append(Path(env_path))
    locations.extend([
        Path(__file__).parent.parent / "mcp_server.mjs",
        Path.cwd() / "mcp_server.mjs"
    ])
    for loc in locations:
        if loc.exists():
            return loc
    print("Error: Cannot find mcp_server.mjs")
    sys.exit(1)


# ── Main ─────────────────────────────────────────────────────

async def main():
    global mcp_session, WORK_DIR, SHOW_PROMPTS, USER_PROMPT

    parser = argparse.ArgumentParser(
        description="Interactive agent for libEnsemble scripts",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python libe_agent_interactive_llm_first.py --interactive
  python libe_agent_interactive_llm_first.py --interactive --scripts my_scripts/
  python libe_agent_interactive_llm_first.py --prompt "Create APOSMM scripts..."
        """
    )
    parser.add_argument("--interactive", action="store_true", help="Enable interactive chat mode")
    parser.add_argument("--scripts", help="Use existing scripts from directory")
    parser.add_argument("--prompt", help="Prompt for script generation")
    parser.add_argument("--prompt-file", help="Read prompt from file")
    parser.add_argument("--show-prompts", action="store_true")
    parser.add_argument("--debug", action="store_true", help="Dump full message log to debug_log.txt")
    parser.add_argument("--mcp-server", help="Path to mcp_server.mjs")
    parser.add_argument("--generate-only", action="store_true")
    parser.add_argument("--max-iterations", type=int, default=15)
    args = parser.parse_args()

    SHOW_PROMPTS = args.show_prompts
    interactive = args.interactive

    global DEBUG_LOG
    if args.debug or os.environ.get("AGENT_DEBUG"):
        DEBUG_LOG = "debug_log.txt"
        with open(DEBUG_LOG, "w") as f:
            f.write(f"Debug log started: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Model: {MODEL}\n\n")

    archive_existing_output_dir("generated_scripts")
    WORK_DIR = Path("generated_scripts")

    # Load skills into system prompt
    skills_text = load_skills()
    system_prompt = SYSTEM_PROMPT.format(skills_context=skills_text)

    if DEBUG_LOG:
        with open(DEBUG_LOG, "a") as f:
            f.write("SYSTEM PROMPT\n" + "="*80 + "\n")
            f.write(system_prompt + "\n\n")

    # Connect to MCP server
    mcp_server = find_mcp_server(args.mcp_server)
    print(f"Generator MCP: {mcp_server}")
    server_params = StdioServerParameters(command="node", args=[str(mcp_server)])

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            mcp_session = session
            print("✓ Connected to MCP server")

            mcp_tools = await session.list_tools()
            mcp_tool = mcp_tools.tools[0]

            mcp_schema = mcp_tool_to_pydantic(mcp_tool)
            tools = [
                StructuredTool(
                    name=mcp_tool.name, description=mcp_tool.description,
                    args_schema=mcp_schema, coroutine=generate_scripts_mcp
                ),
                StructuredTool(name="run_script", description="Run a Python script. Returns SUCCESS or FAILED with error details.", args_schema=RunScriptInput, coroutine=run_script_tool),
                StructuredTool(name="read_file", description="Read a file to inspect its contents.", args_schema=ReadFileInput, coroutine=read_file_tool),
                StructuredTool(name="write_file", description="Write/overwrite a file to fix scripts.", args_schema=WriteFileInput, coroutine=write_file_tool),
                StructuredTool(name="list_files", description="List Python files in working directory.", args_schema=ListFilesInput, coroutine=list_files_tool),
            ]

            if DEBUG_LOG:
                with open(DEBUG_LOG, "a") as f:
                    f.write("TOOL SCHEMAS\n" + "="*80 + "\n")
                    for t in tools:
                        f.write(f"\n{t.name}: {t.description}\n")
                        if t.args_schema:
                            f.write(f"  Schema: {t.args_schema.schema()}\n")

            llm = create_llm(MODEL, base_url=os.environ.get("OPENAI_BASE_URL"))
            agent = create_agent(llm, tools, system_prompt=system_prompt)
            print("✓ Agent initialized\n")

            # Build initial user message
            messages = []

            if args.scripts:
                scripts_dir = Path(args.scripts)
                for f in sorted(scripts_dir.glob("*.py")):
                    shutil.copy(f, WORK_DIR)
                    print(f"Copied: {f.name}")
                start_new_archive("copied_scripts")
                archive_current_scripts()
                run_scripts = list(WORK_DIR.glob("run_*.py"))
                run_name = run_scripts[0].name if run_scripts else "run_libe.py"
                initial_msg = f"I have libEnsemble scripts. The main script is '{run_name}'. Please review them and highlight the key configuration."
            elif args.prompt:
                initial_msg = args.prompt
            elif args.prompt_file:
                initial_msg = Path(args.prompt_file).read_text()
            elif interactive:
                print("Describe the scripts you want to generate (or press Enter for default demo):", flush=True)
                print(INPUT_MARKER, flush=True)
                user_input = input().strip()
                initial_msg = user_input if user_input else DEFAULT_PROMPT
                if not user_input:
                    print("Using default demo prompt")
            else:
                initial_msg = DEFAULT_PROMPT

            USER_PROMPT = initial_msg

            if not interactive:
                # Autonomous: single invocation
                goal = f"{initial_msg}\n\nAfter generating/loading scripts: review them, run them, fix errors and retry (max 3 attempts). Report the result."
                messages.append(HumanMessage(content=goal))
                if SHOW_PROMPTS:
                    print(f"Goal: {goal}\n")
                print("Starting agent...\n")
                result = await agent.ainvoke({"messages": messages})
                dump_messages(result["messages"], "Autonomous run complete")
                print(f"\n{'='*60}")
                print("✓ Agent completed")
                print(f"{'='*60}")
                print(result["messages"][-1].content)
            else:
                # Interactive: chat loop
                messages.append(HumanMessage(content=initial_msg))
                print("Starting agent...\n")

                turn = 0
                while True:
                    try:
                        result = await agent.ainvoke({"messages": messages})
                        messages = result["messages"]
                        turn += 1
                        dump_messages(messages, f"Interactive turn {turn}")
                        response = messages[-1].content
                        if response:
                            print(f"\n{response}", flush=True)
                    except Exception as e:
                        print(f"\n⚠️ Agent error: {e}", flush=True)

                    print(INPUT_MARKER, flush=True)
                    user_input = input().strip()

                    if not user_input or user_input.lower() in ('quit', 'exit', 'done'):
                        print("\n✓ Session ended")
                        break

                    messages.append(HumanMessage(content=user_input))


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nInterrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"\n✗ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
